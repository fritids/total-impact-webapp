{% extends "base.html" %}

{% block content %}

<h2><span class="wrapper">about</span></h2>
<div id="faq"><div class="wrapper">
<div id="toc"></div>

<h3 id="what">what is total-impact?</h3>

<p>Total-impact is a website that makes it quick and easy to view the impact of a wide range of research output. It goes beyond traditional measurements of research output -- citations to papers -- to embrace a much broader evidence of use across a wide range of scholarly output types. The system aggregates impact data from many sources and displays it in a single report, which is given a permaurl for dissemination and can be updated any time.

<h3 id="audience">who is it for?</h3>

<ul>
<li><b>researchers</b> who want to know how many times their work has been downloaded, bookmarked, and blogged
<li><b>research groups</b> who want to look at the broad impact of their work and see what has demonstrated interest
<li><b>funders</b> who want to see what sort of impact they may be missing when only considering citations to papers
<li><b>repositories</b> who want to report on how their research artifacts are being discussed
<li><b>all of us</b> who believe that people should be rewarded when their work (no matter what the format) makes a positive impact (no matter what the venue). Aggregating evidence of impact will facilitate appropriate rewards, thereby encouraging additional openness of useful forms of research output.
</ul>

<h3 id="uses">how should it be used?</h3>

Total-impact data can be:
<ul>
<li>highlighted as indications of the <em>minimum</em> impact a research artifact has made on the community
<li>explored more deeply to see who is citing, bookmarking, and otherwise using your work
<li>run to collect usage information for mention in biosketches
<li>included as a link in CVs
<li>analyzed by downloading detailed metric information
</ul>

<h3 id="pooruses">how <em>shouldn’t</em> it be used?</h3>

<p>Some of these issues relate to the early-development phase of total-impact, some reflect our early-understanding of altmetrics, and some are just common sense. Total-impact reports shouldn't be used:

<ul>
<li><b>as indication of comprehensive impact</b>
<p>Total-impact is in early development. See <a href="#limitations">limitations</a> and take it all with a grain of salt.

<li><b>for serious comparison</b>
<p>Total-impact is currently better at collecting comprehensive metrics for some artifacts than others, in ways that are not clear in the report. Extreme care should be taken in comparisons. Numbers should be considered minimums. Even more care should be taken in comparing collections of artifacts, since some total-impact is currently better at identifying artifacts identified in some ways than others. Finally, some of these metrics can be easily gamed. This is one reason we believe having many metrics is valuable.

<li><b>as if we knew exactly what it all means</b>
<p>The meaning of these metrics are not yet well understood; see <a href="#meaning">section</a> below.

<li><b>as a substitute for personal judgement of quality</b>
<p>Metrics are only one part of the story. Look at the research artifact for yourself and talk about it with informed colleagues.

</ul>

<h3 id="meaning">what do these number actually mean?</h3>

<p>The short answer is: probably something useful, but we’re not sure what. We believe that dismissing the metrics as “buzz” is short-sited: surely people bookmark and download things for a reason. The long answer, as well as a lot more speculation on the long-term significance of tools like total-impact, can be found in the nascent scholarly literature on “altmetrics.”

<p><a href="http://altmetrics.org/manifesto/">The Altmetrics Manifesto</a> is a good, easily-readable introduction to this literature, while the proceedings of the recent <a href="http://altmetrics.org/workshop2011/">altmetrics11</a> and <a href="http://altmetrics.org/altmetrics12/">altmetrics12</a> workshops go into more detail. You can check out the shared <a href="http://www.mendeley.com/groups/586171/alt-metrics/papers/">altmetrics library</a> on Mendeley for more even relevant research. Finally, the poster <a href="http://jasonpriem.com/self-archived/two-altmetrics-tools.pdf">Uncovering impacts: CitedIn and total-impact, two new tools for gathering altmetrics</a>, recently submitted to the 2012 iConference, describes a case study using total-impact to evaluate a set of research papers funded by NESCent; it has some brief statistical analysis and some visualisations of the results.

{{ which_artifacts|safe() }}

<h3 id="whichmetrics">which metrics are measured?</h3>

<p>Metrics are computed based on the following data sources:</p>

<ul id="providers-metadata"> <!-- list of providers -->
{% for provider_name, provider in provider_metadata.iteritems() %}
    {% if provider.metrics %}
    <li> <!-- the provider -->
        <a href="{{ provider.url }}">{{ provider_name }}</a> <span class="descr">{{ provider.descr|safe() }}</span>
        <ul> <!-- list of metrics supplied by this provider -->
            {% for metric_name, metric in provider.metrics.iteritems() %}
            <li> <!-- information about a particular metric -->
                <img src="{{ metric.icon }}" width="16" height="16" />
                <strong>{{ metric_name }}</strong>
                <span class="metric-descr">{{ metric.description }}</span>
            </li>
            {% endfor %}
        </ul>
    </li>
    {% endif %}
{% endfor %}
</ul>

<h3 id="whereisif">where is the journal impact factor?</h3>

<p>We do not include the Journal Impact Factor (or any similar proxy) on purpose. As has been <a href="https://www.zotero.org/groups/impact_factor_problems/items">repeatedly shown</a>, the Impact Factor is not appropriate for judging the quality of individual research artifacts. Individual article citations reflect much more about how useful papers actually were. Better yet are article-level metrics, as initiated by PLoS, in which we examine traces of impact beyond citation. Total-impact broadens this approach to reflect <b>artifact-level metrics</b>, by inclusion of preprints, datasets, presentation slides, and other research output formats.

<h3 id="similar">where is my other favourite metric?</h3>

<p>We only include open metrics here, and so far only a selection of those. We welcome contributions of plugins. Write your own and tell us about it.

<p>Not sure total-impact is your cup of tea?  Check out these similar tools:
<ul>
<li><a href="http://altmetric.com">altmetric.com</a>
<li><a href="http://http://www.plumanalytics.com/">Plum Analytics</a>
<li><a href="http://code.google.com/p/alt-metrics/">PLoS Article-Level Metrics application</a>
<li><a href="http://sciencecard.org/">Science Card</a>
<li><a href="http://citedin.org/">CitedIn</a>
<li><a href="http://readermeter.org/">ReaderMeter</a>
</ul>

<h3 id="limitations">what are the current limitations of the system?</h3>

<p>Total-impact is in early development and has many limitations. Some of the ones we know about:

<h3>gathering IDs sometimes misses artifacts</h3>
<ul>
<li>BibTex import sometimes can't parse or locate all objects
</ul>

<h3>artifacts are sometimes missing metrics</h3>
<ul>
<li>doesn’t display metrics with a zero value
<li>sometimes the artifacts were received without sufficient information to use all metrics. For example, the system sometimes can't figure out all URLs from a DOI.
</ul>

<h3>metrics sometimes have values that are too low</h3>
<ul>
<li>some sources have multiple records for a given artifact. Total-impact only identifies one copy and so only reports the impact metrics for that record. It makes no current attempt to aggregate across duplications within a source.
</ul>

<h3>other</h3>
<ul>
<li>the number of items on a report is currently limited.
</ul>

Tell us about bugs! <a href="http://twitter.com/#!/totalImpactdev">@totalImpactdev</a> (or via email to total-impact@googlegroups.com)

<h3 id="isitopen">is this data Open?</h3>

<p>We’d like to make all of the data displayed by total-impact available under CC0. Unfortunately, the terms-of-use of most of the data sources don’t allow that. We're trying to figure out how to handle this.
<p>An option to restrict the displayed reports to Fully Open metrics — those suitable for commercial use — is on the To Do list.
<p>The total-impact software itself is fully open source under an MIT license. <a href="https://github.com/total-impact">GitHub</a>

<h3 id="api">does total-impact have an api?</h3>

<p>yes! Total-impact is built on its own api, and others may build on it too.
<p>We also have javascript to make embedding total-impact data very easy.  We'll document it soon: contact us for details in the meantime.


<h3 id="who">who developed total-impact?</h3>

<p>Concept originally hacked at the <a href="http://www.beyond-impact.org/">Beyond Impact Workshop</a>, part of the Beyond Impact project funded by the Open Society Foundations <a href="https://github.com/mhahnel/total-impact/contributors">(initial contributors)</a>.

<h3 id="funding">who funds total-impact?</h3>

<p>Early development was done on personal time, plus some discretionary time while funded through <a href="http://dataone.org">DataONE</a> (Heather Piwowar) and a <a href="http://gradschool.unc.edu/programs/royster">UNC Royster Fellowship</a> (Jason Priem). 

<p>In early 2012, total-impact was given £17,000 through the <a href="http://www.beyond-impact.org/">Beyond Impact project</a> from the <a href="http://www.soros.org/">Open Society Foundation</a>.  As of May 2012, total-impact is funded through a $125k grant from the <a href="http://sloan.org/">Alfred P. Sloan Foundation. </a>

<h3 id="learned">what have you learned?</h3>

<ul>
<li>the multitude of IDs for a given artifact is a bigger problem than we guessed. Even articles that have DOIs often also have urls, PubMed IDs, PubMed Central IDs, Mendeley IDs, etc. There is no one place to find all synonyms, yet the various APIs often only work with a specific one or two ID types. This makes comprehensive impact-gathering time consuming and error-prone.
<li>some data is harder to get than we thought (wordpress stats without requesting consumer key information)
<li>some data is easier to get than we thought (vendors willing to work out special agreements, permit web scraping for particular purposes, etc)
<li>lack of an author-identifier makes us reliant on user-populated systems like Mendeley for tracking author-based work (we need ORCID and we need it now!)
<li>API limits like those on PubMed Central (3 request per second) make their data difficult to incorporate in this sort of application
</ul>

<h3 id="howhelp">how can I help?</h3>

<ul>
<li><b>do you have data?</b> If it is already available in some public format, let us know so we can add it. If it isn’t, either please open it up or contact us to work out some mutually beneficial way we can work together.
<li><b>do you have money?</b> We need money :) We need to fund future development of the system and are actively looking for appropriate opportunities.
<li><b>do you have ideas?</b> Maybe enhancements to total-impact would fit in with a grant you are writing, or maybe you want to make it work extra-well for your institution’s research outputs. We’re interested: please get in touch (see bottom).
<li><b>do you have energy?</b> We need better “see what it does” documentation, better lists of collections, etc. Make some and tell us, please!
<li><b>do you have anger that your favourite data source is missing?</b> After you confirm that its data isn't available for open purposes like this, write to them and ask them to open it up... it might work. If the data is open but isn't included here, let us know to help us prioritize.
<li><b>can you email, blog, post, tweet, or walk down the hall to tell a friend?</b> See the <a href="#cool">this is so cool</a> section for your vital role....
</ul>

<h3 id="cool">this is so cool.</h3>

<p>Thanks! We agree :)
<p>You can help us.  Demonstrating the value of total-impact is key to recieving future funding.
<p>Buzz and testimonials will help. Tweet your reports. Blog, send email, and show off total-impact at your next group meeting to help spread the word.
<p>Tell us how cool it is at <a href="http://twitter.com/#!/totalImpactdev">@totalImpactdev</a> (or via email to total-impact@googlegroups.com) so we can consolidate the feedback.

<h3 id="suggestion">I have a suggestion!</h3>

<p><b>We want to hear it.</b> Send it to us at <a href="http://twitter.com/#!/totalImpactdev">@totalImpactdev</a> (or via email to total-impact@googlegroups.com). 
</div><!-- end wrapper -->
</div><!-- end faq -->
</div>

{% endblock %}
